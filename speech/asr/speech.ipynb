{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%script echo\n",
    "%pip install transformers\n",
    "%pip install tf-keras\n",
    "%pip uninstall -y tensorflow tensorflow-macos tensorflow-metal keras\n",
    "%pip install --upgrade pip\n",
    "%pip install tensorflow==2.16.1 tensorflow-metal==1.1.0 keras==3.0.0 \n",
    "%pip install pydub\n",
    "# install ffmpeg: pydub relies on ffprobe to process audio files like MP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                        # Operating system-related functions (file, directory operations)\n",
    "import sys                                       # Provides access to system-specific parameters and functions\n",
    "import platform                                  # Provides functions and information about the operating system and hardware\n",
    "\n",
    "import numpy as np                               # numerical operations & array manipulation\n",
    "import pickle                                    # for object serialization & deserialization\n",
    "import random                                    # generates random numbers\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt                  # creating plots & visualizations\n",
    "\n",
    "# import cv2                                       # computer vision & image processing\n",
    "import tensorflow as tf                          # deep learning framework\n",
    "import keras                                     # training & evaluating deep learning models\n",
    "import transformers\n",
    "\n",
    "from tqdm import tqdm                            # creating progress bars in loops\n",
    "from typing import Dict, List, Tuple, Optional   # type hinting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 24.3.1 from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pip (python 3.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%conda --version\n",
    "%pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating System: Darwin 24.0.0\n",
      "Python Platform: macOS-15.0-arm64-arm-64bit\n",
      "Python Version: 3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "\n",
      "NumPy Version: 1.26.3\n",
      "TensorFlow Version: 2.16.1\n",
      "Keras Version: 3.0.0\n",
      "Transformers Version: 4.47.0\n"
     ]
    }
   ],
   "source": [
    "# Check Operating System & Platform\n",
    "print('Operating System:', platform.system(), platform.release())\n",
    "print('Python Platform:', platform.platform())\n",
    "\n",
    "# Check Python Version\n",
    "print('Python Version:', sys.version)\n",
    "print()\n",
    "\n",
    "# Print library versions\n",
    "print('NumPy Version:', np.__version__)\n",
    "# print('OpenCV Version:', cv2.__version__)\n",
    "print('TensorFlow Version:', tf.__version__)\n",
    "print('Keras Version:', keras.__version__)\n",
    "print('Transformers Version:', transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "\n",
    "Create a hosted microservice to deploy an Automatic Speech Recognition (ASR) AI model that can be used to transcribe any audio files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2a**\n",
    "\n",
    "AI model to use: wav2vec2-large-960h\n",
    "https://huggingface.co/facebook/wav2vec2-large-960h\n",
    "This model is developed by Facebook and pretrained and fine-tuned on Librispeech dataset on 16kHz sampled speech audio. Please ensure that your speech input is also sampled at 16kHz. The reference link (above) includes the model card and its usage code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# # Use a pipeline as a high-level helper\n",
    "# from transformers import pipeline\n",
    "# pipe = pipeline('automatic-speech-recognition', model='facebook/wav2vec2-large-960h')\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "\n",
    "# Load processor and model using downloaded paths\n",
    "processor = AutoProcessor.from_pretrained('facebook/wav2vec2-large-960h')\n",
    "model = AutoModelForCTC.from_pretrained('facebook/wav2vec2-large-960h')\n",
    "\n",
    "model_dir = 'model'\n",
    "processor.save_pretrained(model_dir)\n",
    "model.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current sample rate: 44.1kHz\n",
      "Audio converted to 16kHz.\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "\n",
    "def get_sample_rate(file_path: str) -> int:\n",
    "    '''\n",
    "    Get the sample rate of an audio file using ffprobe.\n",
    "    '''\n",
    "    try:\n",
    "        command = [\n",
    "            'ffprobe',\n",
    "            '-v', 'error',\n",
    "            '-select_streams', 'a:0',\n",
    "            '-show_entries', 'stream=sample_rate',\n",
    "            '-of', 'default=noprint_wrappers=1:nokey=1',\n",
    "            file_path\n",
    "        ]\n",
    "        result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        return int(result.stdout.strip())\n",
    "    except Exception as e:\n",
    "        print(f'Error retrieving sample rate: {e}')\n",
    "        return -1\n",
    "\n",
    "audio_dir = 'audio'\n",
    "ding_dir = 'harvard.wav'\n",
    "file_dir = os.path.join(audio_dir, ding_dir)\n",
    "\n",
    "# Get the current sample rate\n",
    "current_sample_rate = get_sample_rate(file_dir)\n",
    "print(f'Current sample rate: {current_sample_rate / 1000}kHz')\n",
    "\n",
    "# Load the MP3 file\n",
    "audio = AudioSegment.from_file(file_dir, format='mp3')\n",
    "\n",
    "# Convert only if the sample rate is not 16kHz\n",
    "if current_sample_rate != 16000:\n",
    "    audio = audio.set_frame_rate(16000).set_channels(1)  # Ensure mono audio\n",
    "    converted_path = os.path.join('audio', 'converted_audio_16kHz.mp3')\n",
    "    audio.export(converted_path, format='mp3')\n",
    "    print('Audio converted to 16kHz.')\n",
    "else:\n",
    "    print('Audio is already at 16kHz. No conversion needed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test ASR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Sampling Rate: 44100\n",
      "Audio converted to 16kHz.\n",
      "Transcription: \n",
      "Audio Sampling Rate: 44100\n",
      "Audio converted to 16kHz.\n",
      "Transcription: THE STALE SMELL OF OLD BEER LINGERS IT TAKES HEAT TO BRING OUT THE ODOUR A COLD DIP RESTORES HEALTH AND ZEST A SALT PICKLE TASTES FINE WITH HAM TACCOS AL PASTORE ARE MY FAVORITE A ZESTFUL FOOD IS THE HOT CROSS BUN\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def load_audio(audio_path: str) -> tuple[torch.Tensor, int, str]:\n",
    "    '''\n",
    "    Load and preprocess the audio file for Wav2Vec2 model.\n",
    "    Args:\n",
    "        audio_path (str): Path to the audio file.\n",
    "    Returns:\n",
    "        torch.Tensor: Preprocessed audio tensor.\n",
    "        int: Sampling rate of the audio.\n",
    "    '''\n",
    "    audio = AudioSegment.from_file(audio_path, format='mp3')\n",
    "    sample_rate = audio.frame_rate\n",
    "    # sample_rate = get_sample_rate(audio_path)\n",
    "    print('Audio Sampling Rate:', sample_rate)\n",
    "\n",
    "    # Convert to 16kHz using pydub if needed\n",
    "    if sample_rate != 16000 and sample_rate > 0: \n",
    "        audio = audio.set_frame_rate(16000).set_channels(1)  # Ensure mono and 16kHz\n",
    "        converted_path = os.path.join('audio', 'converted_audio_16kHz.mp3')\n",
    "        audio.export(converted_path, format='mp3')\n",
    "        print('Audio converted to 16kHz.')\n",
    "        audio_dir = converted_path\n",
    "    \n",
    "    audio = AudioSegment.from_file(audio_dir, format='mp3')\n",
    "    new_sample_rate = audio.frame_rate\n",
    "\n",
    "    # Convert to 16-bit PCM samples\n",
    "    samples = audio.get_array_of_samples()    \n",
    "    # Convert to a PyTorch tensor\n",
    "    waveform = torch.tensor(samples, dtype=torch.float32) / (2 ** 15)  # Normalize to [-1, 1]\n",
    "    \n",
    "    # Ensure waveform shape is compatible\n",
    "    if audio.channels > 1:\n",
    "        waveform = waveform.reshape(audio.channels, -1).mean(dim=0)  # Downmix to mono\n",
    "\n",
    "    return waveform.unsqueeze(0), new_sample_rate, audio_dir\n",
    "\n",
    "def transcribe_audio(audio_path: str, model_dir: str) -> str:\n",
    "    '''\n",
    "    Transcribe the given audio file using a pre-trained Wav2Vec2 model.\n",
    "    Args:\n",
    "        audio_path (str): Path to the audio file.\n",
    "        model_dir (str): Directory containing the saved model and processor.\n",
    "    Returns:\n",
    "        str: Transcription of the audio.\n",
    "    '''\n",
    "    # Load the processor and model\n",
    "    processor = AutoProcessor.from_pretrained(model_dir)\n",
    "    model = AutoModelForCTC.from_pretrained(model_dir)\n",
    "\n",
    "    # Load and preprocess the audio\n",
    "    waveform, sample_rate, audio_dir = load_audio(audio_path)\n",
    "\n",
    "    # Prepare inputs for the model\n",
    "    inputs = processor(waveform.squeeze().numpy(), sampling_rate=sample_rate, return_tensors='pt', padding=True)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    # Decode the predicted IDs to text\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "    return transcription[0]\n",
    "\n",
    "# File paths\n",
    "model_dir = 'model'\n",
    "audio_file_1 = 'dingSFX-1.mp3'\n",
    "audio_file_2 = 'harvard.wav'\n",
    "\n",
    "# Transcript Audio File 1: dingSFX-1.mp3\n",
    "audio_path = os.path.join(audio_dir, audio_file_1)\n",
    "transcription = transcribe_audio(audio_path, model_dir)\n",
    "print(f'Transcription: {transcription}')\n",
    "\n",
    "# Transcript Audio File 2: harvard.wav\n",
    "audio_path = os.path.join(audio_dir, audio_file_2)\n",
    "transcription = transcribe_audio(audio_path, model_dir)\n",
    "print(f'Transcription: {transcription}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
